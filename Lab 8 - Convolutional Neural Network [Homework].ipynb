{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eijcmIWOr39B"
   },
   "source": [
    "# **2110433 - Computer Vision (2023/2)**\n",
    "#**Lab 8 - Convolutional Neural Network [Homework]** <br>\n",
    "In this lab, we will learn how to use Convolutional Neural Network to perform image classification in the provided real world dataset using PyTorch. This notebook includes both coding and written questions. Please hand in this notebook file with all outputs and your answer.\n",
    "\n",
    "**Collaboration is encouraged in this course.** You must turn in your own write ups of all problems. If you collaborate with others, you must put the names and ids of the students you worked with in below block.\n",
    "\n",
    "Collaboration List:\n",
    "- ...\n",
    "- ...\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "q51z8PMXfLyh"
   },
   "source": [
    "# Assignment 1 : Food Image Classification\n",
    "![alt text](https://cdn.pixabay.com/photo/2015/08/26/10/58/the-pork-fried-rice-made-908333_1280.jpg)\n",
    "\n",
    "Classify 50 food menus from Chula-Food-50 dataset\n",
    " \n",
    "\n",
    "In this assignment you have to replace YOUR_STUDENT_ID_WITH21 variable with your student id (in integer). There will be 2 sets of data: train and test \n",
    "\n",
    "By using the knowledge from the lab and lecture, you have to design your own CNN food image classification model and tested on unknown label dataset!\n",
    "\n",
    "\n",
    "\n",
    "Scoreboard URL : https://www.piclab.ai/classes/cv2023/lab8/scoreboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynMThy4kbk4G"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib\n",
    "from matplotlib import font_manager\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision import models as models\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "##### Add Thai font ######\n",
    "\n",
    "!wget https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
    "font_manager.fontManager.addfont(path= 'thsarabunnew-webfont.ttf')\n",
    "matplotlib.rc('font', family='TH Sarabun New')\n",
    "\n",
    "##### Don't forget to put your ID here (in integer) ####\n",
    "YOUR_STUDENT_ID_WITH21 = 5630008021 \n",
    "#######################################################\n",
    "\n",
    "def isStudentIDValid(studentID):\n",
    "  strID = str(studentID)\n",
    "  isEndWith21 = strID.endswith('21')\n",
    "  isLengthOK = len(strID) == 10\n",
    "  if isEndWith21 and isLengthOK:\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "print('Student ID status:',isStudentIDValid(YOUR_STUDENT_ID_WITH21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9zPv07crmK9"
   },
   "source": [
    "## Your model description goes here: ###\n",
    "WRITE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LDDMTmU8f7AJ"
   },
   "source": [
    "## GPU Status Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkMFsz71gFUy"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItsX7viBgHVS"
   },
   "source": [
    "## Download and inspect Chula-Food-50 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPKXJyE8cKV0"
   },
   "outputs": [],
   "source": [
    "!wget  -O chula-food-50.zip https://piclab.ai/classes/cv2021/Chula-food-50.zip\n",
    "!unzip -qo chula-food-50.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOUMO-oRgPIe"
   },
   "outputs": [],
   "source": [
    "### Helper function to display image from dataset ###\n",
    "def getImageFromDataset(dataset, idx):\n",
    "  sampleImage, sampleLabel = dataset.__getitem__(idx)\n",
    "  ### Revert transformation ###\n",
    "  sampleImage = ((sampleImage.permute(1,2,0).numpy() * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406]))*255\n",
    "  sampleImage = sampleImage.astype(np.uint8)\n",
    "  sampleClassName = dataset.classes[sampleLabel]\n",
    "  return sampleImage, sampleClassName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ALFZbGlOb0QL"
   },
   "outputs": [],
   "source": [
    "#### FILL Any Augmenetation HERE ####\n",
    "transformTrain = transforms.Compose([\n",
    "        transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "\n",
    "transformVal =  transforms.Compose([\n",
    "        transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "### Load Dataset ###\n",
    "foodTrainDataset =\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split train and validation ###\n",
    "TEST_SIZE = 0.1\n",
    "SEED = 42\n",
    "BATCH_SIZE = 16\n",
    "# generate indices: instead of the actual data we pass in integers instead\n",
    "train_indices, test_indices, _, _ = train_test_split(\n",
    "    range(len(foodTrainDataset)),\n",
    "    foodTrainDataset.targets,\n",
    "    stratify=foodTrainDataset.targets,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# generate subset based on indices\n",
    "train_split = Subset(foodTrainDataset, train_indices)\n",
    "test_split = Subset(foodTrainDataset, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtY4pFYLgXMb",
    "tags": []
   },
   "source": [
    "## Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygdZ_mQ7gV95"
   },
   "outputs": [],
   "source": [
    "image1, image1ClassName = getImageFromDataset(foodTrainDataset, 0)\n",
    "image2, image2ClassName = getImageFromDataset(foodTrainDataset, 1600)\n",
    "\n",
    "_, figure = plt.subplots(1,2)\n",
    "\n",
    "figure[0].imshow(image1,cmap='gray')\n",
    "figure[0].set_title(image1ClassName)\n",
    "figure[1].imshow(image2,cmap='gray')\n",
    "figure[1].set_title(image2ClassName)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SbeT8fTgprL"
   },
   "source": [
    "## Define CNN network for food classification\n",
    "Hint\n",
    "1. You can freely uses any structure/pretrained model to do this homework but don't forgot to cited them in this notebook.\n",
    "\n",
    "   A very big collection of pretrained model can be found here : https://github.com/rwightman/pytorch-image-models\n",
    "\n",
    "2. Don't forget to change mean and std in the pre-processing to match with your pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9UgoSjIb57S"
   },
   "outputs": [],
   "source": [
    "#### Design you network here ####\n",
    "class foodNet(nn.Module):\n",
    "  def __init__(self,)\n",
    "    super(foodNet, self).__init__()\n",
    "    ### Layers goes here ###\n",
    "  def forward(self, input):\n",
    "    ### Conntections goes here ###\n",
    "    return ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2uj_-gTgxIw"
   },
   "source": [
    "## Construct the model, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3ysKN-AcNnO"
   },
   "outputs": [],
   "source": [
    "#### FILL HERE ####\n",
    "foodNet.cuda()\n",
    "\n",
    "criterion = \n",
    "optimizer = \n",
    "scheduler =\n",
    "\n",
    "foodTrainDatasetLoader = \n",
    "foodValDatasetLoader = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nj-2hcRGg54i"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9ViDa1Cda7d"
   },
   "outputs": [],
   "source": [
    "### Train and test helper function ###\n",
    "def testModel(testDatasetLoader, net):\n",
    "  net.eval()\n",
    "  correctImages = 0\n",
    "  totalImages = 0\n",
    "  allLabels = []\n",
    "  allPredicted = []\n",
    "  testingProgressbar = tqdm(enumerate(testDatasetLoader), total=len(testDatasetLoader), ncols=100)\n",
    "  with torch.no_grad():\n",
    "    for batchIdx, batchData in testingProgressbar:\n",
    "      images, labels = batchData\n",
    "      \n",
    "      images, labels = images.cuda(), labels.cuda()\n",
    "      outputs = net(images)\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "      correctImages += (predicted == labels).sum().item()\n",
    "      totalImages += labels.size(0)\n",
    "\n",
    "      accumulateAccuracy = round((correctImages/totalImages)*100,4)\n",
    "      testingProgressbar.set_description(\"Testing accuracy: {}\".format(accumulateAccuracy ) )\n",
    "    \n",
    "      allLabels.append(labels)\n",
    "      allPredicted.append(predicted)\n",
    "  allLabels = torch.cat(allLabels).cpu().numpy()\n",
    "  allPredicted = torch.cat(allPredicted).cpu().numpy()\n",
    "  return correctImages, totalImages, allLabels, allPredicted\n",
    "\n",
    "def trainAndTestModel(trainDatasetLoader, testDatasetLoader, net, optimizer,scheduler, criterion, trainEpoch):\n",
    "  \n",
    "  bestAccuracy = 0\n",
    "  correctImages = 0\n",
    "  totalImages = 0\n",
    "  for currentEpoch in tqdm(range(trainEpoch), desc='Overall Training Progress:', ncols=100):\n",
    "    trainingLoss = 0.0\n",
    "    net.train()\n",
    "    print('Epoch',str(currentEpoch+1),'/',str(trainEpoch))\n",
    "    trainingProgressbar = tqdm(enumerate(trainDatasetLoader), total=len(trainDatasetLoader), ncols=100)\n",
    "    for batchIdx, batchData in trainingProgressbar:\n",
    "      images, labels = batchData\n",
    "      images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "      # zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # forward + backward + optimize\n",
    "      outputs = net(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "    \n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      correctImages += (predicted == labels).sum().item()\n",
    "      totalImages += labels.size(0)\n",
    "    \n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "\n",
    "      trainingLoss += loss.item()\n",
    "      accumulateAccuracy = round((correctImages/totalImages)*100,4)\n",
    "      trainingProgressbar.set_description(\"Training accuracy: {} loss: {}\".format(accumulateAccuracy, round(loss.item(),4) ) )\n",
    "    scheduler.step(trainingLoss)\n",
    "    correctImages, totalImages, allLabels, allPredicted = testModel(testDatasetLoader, net)\n",
    "    testAccuracy = round((correctImages/totalImages)*100,2)\n",
    "\n",
    "    print('='*10)\n",
    "    \n",
    "    if testAccuracy > bestAccuracy:\n",
    "      bestAccuracy = testAccuracy\n",
    "      bestPredicted = allPredicted\n",
    "      bestNet = net\n",
    "\n",
    "  return bestAccuracy, bestPredicted, allLabels, bestNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ogG_MRacSjm"
   },
   "outputs": [],
   "source": [
    "bestAccuracy, bestPredicted, allLabels, bestNet = trainAndTestModel(??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcJEcscDhD6D"
   },
   "source": [
    "## Classify on validation set and send result to server!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S59bPBW3duMw"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import json\n",
    "import requests\n",
    "\n",
    "class ImageFolderWithPaths(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.imageFileNames = sorted(glob.glob(root_dir+'/*.jpg'))\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        imageData = Image.open(self.imageFileNames[idx])\n",
    "        imageFileName = os.path.basename(self.imageFileNames[idx])\n",
    "        if self.transform is not None:\n",
    "            imageData = self.transform(imageData)\n",
    "        return imageFileName, imageData.unsqueeze(0)\n",
    "    def __len__(self):\n",
    "        return len(self.imageFileNames)\n",
    "\n",
    "\n",
    "\n",
    "def generatePredictedResults(valDataset, net):\n",
    "    net.eval()\n",
    "    predictedResults = {}\n",
    "    with torch.no_grad():\n",
    "        for imageFileName, imageData in tqdm(valDataset, ncols=100):\n",
    "            imageData = imageData.cuda()\n",
    "            outputs = net(imageData)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            #print(imageFileName, predicted.item())\n",
    "            predictedResults[imageFileName] =  foodTrainDataset.classes[predicted.item()]\n",
    "    return predictedResults\n",
    "\n",
    "def sendResult(predictedResults,studentID=5630008021):\n",
    "    sendDict = { 'studentID':studentID, 'results':  predictedResults }\n",
    "    response = requests.post('https://www.piclab.ai/classes/cv2022/lab8/scoreboard/submit',headers={'Content-Type': 'application/json' }, json=sendDict)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OJAvoBVpkEE"
   },
   "source": [
    "Example Result JSON <br>\n",
    "resultDict = { \n",
    "  'studentID': 555555555521,\n",
    "  'results':{\n",
    "    '1.jpg':'ต้มเลือดหมู',\n",
    "    '2.jpg':'บะหมี่แห้ง',\n",
    "    ...\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUajK45GeA3n"
   },
   "outputs": [],
   "source": [
    "foodTestDataset = ImageFolderWithPaths('test', transform=transformTest)\n",
    "predictedResults = generatePredictedResults(foodTestDataset, bestNet)\n",
    "print(sendResult(predictedResults, studentID=YOUR_STUDENT_ID_WITH21))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab 8 - Convolutional Neural Network [Homework]",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
